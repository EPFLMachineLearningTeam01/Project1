{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "f\n",
    "import csv\n",
    "import importlib\n",
    "from scripts import proj1_helpers, helpers\n",
    "from scripts import implementation, feature_processing, k_fold, model_linear\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_path = '../data/train.csv'\n",
    "test_path  = '../data/test.csv'\n",
    "output_path = '../data/logreg_submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# loading data\n",
    "y, X, idx = proj1_helpers.load_csv_data(train_path)\n",
    "y_t, X_t, ids_t = proj1_helpers.load_csv_data(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_p = feature_processing.process_X(X)\n",
    "X_t_p = feature_processing.process_X(X_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.00000000e+00,   3.14910656e-01,   6.83319669e-02, ...,\n",
       "         -6.70555834e-01,   1.99057407e+00,  -3.11898221e-01],\n",
       "       [  1.00000000e+00,   7.40827026e-01,   5.52504823e-01, ...,\n",
       "          1.49130013e+00,  -5.02367642e-01,  -3.11898221e-01],\n",
       "       [  1.00000000e+00,  -9.69035940e-13,   3.19515553e+00, ...,\n",
       "          1.49130013e+00,  -5.02367642e-01,  -3.11898221e-01],\n",
       "       ..., \n",
       "       [  1.00000000e+00,  -3.10930673e-01,   3.19316447e-01, ...,\n",
       "          1.49130013e+00,  -5.02367642e-01,  -3.11898221e-01],\n",
       "       [  1.00000000e+00,  -5.10097335e-01,  -8.45323970e-01, ...,\n",
       "         -6.70555834e-01,  -5.02367642e-01,  -3.11898221e-01],\n",
       "       [  1.00000000e+00,  -9.69035940e-13,   6.65336083e-01, ...,\n",
       "         -6.70555834e-01,  -5.02367642e-01,  -3.11898221e-01]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-fe9e2cf4e9cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_linear\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_reg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mk_fold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_validation_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_fold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_plot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/repos/git/EPFL/ML/Project1/src/scripts/k_fold.py\u001b[0m in \u001b[0;36mcross_validation_select\u001b[0;34m(x, y, model, loss, kw_model, kw_loss, seed, k_fold, N, do_plot)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             [rmse_[i].append(x) for i, x in\n\u001b[0;32m---> 56\u001b[0;31m              enumerate(cross_validation(y, x, k_indices, k, model, kw_model, loss, kw_loss, lambda_))]\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mrmse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrmse_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mrmse_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrmse_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/repos/git/EPFL/ML/Project1/src/scripts/k_fold.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(y, tx, k_indices, k, model, kw_model, loss, kw_loss, lambda_)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m# training ridge regression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m# computing losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/repos/git/EPFL/ML/Project1/src/scripts/implementation.py\u001b[0m in \u001b[0;36mridge_regression\u001b[0;34m(y, tx, lambda_)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;34m\"\"\"implement ridge regression.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpinv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mtx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlambda_\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2.\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtx\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mN\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlambda_\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = implementation.ridge_regression\n",
    "loss = model_linear.compute_loss_reg\n",
    "\n",
    "idx_min, rmse_all, lambdas = k_fold.cross_validation_select(X_p, y, model, loss, seed = 1, k_fold = 5, N = 20, do_plot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias-Variance Decomposition\n",
    "Visualize bias-variance trade-off by implementing the function `bias_variance_demo()` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from implementation import least_squares\n",
    "from split_data import split_data\n",
    "from plots import bias_variance_decomposition_visualization\n",
    "\n",
    "def bias_variance_demo(ridge_lambda = 0, use_cv = 0):\n",
    "    \"\"\"The entry.\"\"\"\n",
    "    # define parameters\n",
    "    seeds = range(100)\n",
    "    num_data = 5000\n",
    "    ratio_train = 0.005\n",
    "    degrees = range(1, 10)\n",
    "    \n",
    "    k_fold = 4\n",
    "    \n",
    "    # define list to store the variable\n",
    "    rmse_tr = np.zeros((len(seeds), len(degrees)))\n",
    "    rmse_te = np.zeros((len(seeds), len(degrees)))\n",
    "    \n",
    "    for index_seed, seed in tqdm(enumerate(seeds)):\n",
    "        np.random.seed(seed)\n",
    "        x = np.linspace(0.1, 2 * np.pi, num_data)\n",
    "        y = np.sin(x) + 0.3 * np.random.randn(num_data).T\n",
    "        \n",
    "        idx_tr, idx_te = split_data(x, y, ratio_train, seed = seed)\n",
    "        \n",
    "        for index_degree, degree in enumerate(degrees):\n",
    "            # building polynomial matrix for whole dataset\n",
    "            #x_poly = build_poly(x, degree)\n",
    "            y,tx = build_model_data(x,y)\n",
    "\n",
    "        \n",
    "            # x data: train/test\n",
    "            x_tr = tx[idx_tr, :]\n",
    "            x_te = tx[idx_te, :]\n",
    "    \n",
    "            # y data: train/test\n",
    "            y_tr = y[idx_tr]\n",
    "            y_te = y[idx_te]\n",
    "\n",
    "            if use_cv:\n",
    "                # selecting lambda:\n",
    "                idx_min, rmse_all, lambdas = cross_validation_select(np.array(x)[idx_tr], y_tr, seed, degree, k_fold)\n",
    "                ridge_lambda = lambdas[idx_min]\n",
    "            \n",
    "            # training ridge regression\n",
    "            if ridge_lambda > 0:\n",
    "                weights = ridge_regression(y_tr, x_tr, ridge_lambda)\n",
    "            else:\n",
    "                weights = least_squares(y_tr, x_tr)\n",
    "\n",
    "            # computing losses\n",
    "            rmse_tr[index_seed, index_degree] = compute_mse(y_tr, x_tr, weights)\n",
    "            rmse_te[index_seed, index_degree] = compute_mse(y_te, x_te, weights)\n",
    "\n",
    "    plt.figure()\n",
    "    bias_variance_decomposition_visualization(degrees, rmse_tr, rmse_te)\n",
    "    plt.boxplot(rmse_tr, positions = degrees)\n",
    "    plt.boxplot(rmse_te, positions = degrees)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# least squares\n",
    "bias_variance_demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ridge\n",
    "bias_variance_demo(ridge_lambda = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ridge with CV for lambda\n",
    "bias_variance_demo(use_cv = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from proj1_helpers import predict_labels\n",
    "from proj1_helpers import create_csv_submission\n",
    "\n",
    "def build_model(lambda_val,name):\n",
    "    X_t = impute_with_mean(x_test)\n",
    "    X_ts, _, _ = helpers.standardize(X_t)\n",
    "    y_t, tx_t = helpers.build_model_data(X_ts, y_test)\n",
    "    \n",
    "    y_m,tx = build_model_data(x,y)\n",
    "    weights = ridge_regression(y_m, tx, lambda_val)\n",
    "    \n",
    "    y_pred=predict_labels(weights,tx_t)\n",
    "    create_csv_submission(ids_test,y_pred,name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "build_model(0.000001,\"submit_csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
